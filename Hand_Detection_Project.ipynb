{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Libraries"
      ],
      "metadata": {
        "id": "06qOy_Q-e42f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install mediapipe\n",
        "import cv2\n",
        "import mediapipe as mp"
      ],
      "metadata": {
        "id": "J5dys7Z9sCnu"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert Protobuf format to Python Dictionary"
      ],
      "metadata": {
        "id": "prOPW5cMfF_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Used to convert protobuf message to a dictionary.\n",
        "from google.protobuf.json_format import MessageToDict\n",
        "from google.colab.patches import cv2_imshow   # For using showing images in Google Collab"
      ],
      "metadata": {
        "id": "ul1xrL33eSFf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using mpHands Model for detection"
      ],
      "metadata": {
        "id": "Ei6Cr9ZPfhZt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing the Model\n",
        "mpHands = mp.solutions.hands\n",
        "hands = mpHands.Hands(\n",
        "\tstatic_image_mode=False,\n",
        "\tmodel_complexity=1,\n",
        "\tmin_detection_confidence=0.75,\n",
        "\tmin_tracking_confidence=0.75,\n",
        "\tmax_num_hands=2)"
      ],
      "metadata": {
        "id": "WdoZVr8reV0w"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Capture the video frames"
      ],
      "metadata": {
        "id": "kPQhv1qYfpXV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Start capturing video from webcam\n",
        "cap = cv2.VideoCapture('/content/WIN_20240422_21_43_27_Pro.mp4')"
      ],
      "metadata": {
        "id": "0IvtUwWZea9T"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main Logic"
      ],
      "metadata": {
        "id": "dD0vr0GEfsqi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "\t# Dividing the incoming feed frame by frame\n",
        "\tsuccess, img = cap.read()\n",
        "\n",
        "\t# Lateral inversion so as to bring mirror effect\n",
        "\timg = cv2.flip(img, 1)\n",
        "\n",
        "\t# Incomming feed is in BGR, to analyse we need to convert to RGB\n",
        "\timgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "\t# Process the RGB image\n",
        "\tresults = hands.process(imgRGB)\n",
        "\n",
        "\t# Hands detected in frame\n",
        "\tif results.multi_hand_landmarks:\n",
        "\n",
        "\t\t# Both Hands are detected in same frame\n",
        "\t\tif len(results.multi_handedness) == 2:\n",
        "\t\t\t\t# Print both hands on the frame itself\n",
        "\t\t\tcv2.putText(img, 'Both Hands', (250, 50),\n",
        "\t\t\t\t\t\tcv2.FONT_HERSHEY_COMPLEX,\n",
        "\t\t\t\t\t\t0.9, (0, 255, 0), 2)\n",
        "\n",
        "\t\t# If Single hand is there\n",
        "\t\telse:\n",
        "\t\t\tfor i in results.multi_handedness:\n",
        "\n",
        "\t\t\t\tprint(MessageToDict(i))\n",
        "\n",
        "\t\t\t\t# Retrieval of data stored in Dictionary\n",
        "\t\t\t\tlabel = MessageToDict(i)[\"classification\"][0][\"label\"]\n",
        "\n",
        "\n",
        "\t\t\t\t#If the value correponding to label in dictionary is \"LEFT\"\n",
        "\n",
        "\t\t\t\tif label == 'Left':\n",
        "\n",
        "\t\t\t\t\t#It means left hand is detected, show \"LEFT HAND\" on left side of frame\n",
        "\t\t\t\t\tcv2.putText(img, label+' Hand',\n",
        "\t\t\t\t\t\t\t\t(20, 50),\n",
        "\t\t\t\t\t\t\t\tcv2.FONT_HERSHEY_COMPLEX,\n",
        "\t\t\t\t\t\t\t\t0.9, (0, 255, 0), 2)\n",
        "\n",
        "\n",
        "\t\t\t\t#If the value correponding to label in dictionary is \"RIGHT\"\n",
        "\t\t\t\tif label == 'Right':\n",
        "\n",
        "\t\t\t\t\t#It means right hand is detected, show \"RIGHT HAND\" on RIGHT side of frame\n",
        "\t\t\t\t\tcv2.putText(img, label+' Hand', (460, 50),\n",
        "\t\t\t\t\t\t\t\tcv2.FONT_HERSHEY_COMPLEX,\n",
        "\t\t\t\t\t\t\t\t0.9, (0, 255, 0), 2)\n",
        "\n",
        "\t# Displaying video feed with all incoming frames\n",
        "\tcv2_imshow(img)\n",
        "\n",
        " \t#If key 'Q' is pressed, terminate the program and destroy all windows\n",
        "\tif cv2.waitKey(1) & 0xff == ord('q'):\n",
        "\t\tbreak\n"
      ],
      "metadata": {
        "id": "SwG6tztFefue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Release all resources at the end"
      ],
      "metadata": {
        "id": "Af1wOxS3fxdi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cv2.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "AIWeYRMWeveE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}